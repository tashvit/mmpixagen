{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data preparation - sketch to pixel art (Model A3)\n",
    "\n",
    "### Create pairs of sketches and pixel art images\n",
    "\n",
    "- TinyHero dataset source: https://www.kaggle.com/datasets/calmness/retro-pixel-characters-generator\n",
    "- Data for transfer learning:\n",
    "    - Anime Faces dataset source: https://www.kaggle.com/datasets/soumikrakshit/anime-faces\n",
    "    - Pokemon data source: https://www.kaggle.com/datasets/zackseliger/pokemon-images-includes-fakemon\n",
    "    - Animal Pack game assets source: https://kenney.nl/assets/animal-pack-redux\n",
    "- Data preparation for model A3 uses data from the `datasets/unprepared_data/input_a3` folder.\n",
    "- Prepared data is saved in `datasets/model_a3_data`\n",
    "- Pix2Pix models requires input images and ground truth images to be combined. These prepared images are stored in the `combined` folder(s) in `datasets/model_a3_data`"
   ],
   "id": "8d011b188d0b8114"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:04.500076Z",
     "start_time": "2024-08-01T19:14:01.675928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, glob, random\n",
    "import common_functions as core\n",
    "\n",
    "# Get path for files needed to prepare data for transfer learning (base model A3)\n",
    "TRANSFER_LEARNING_DATA = core.get_path(core.A3_BASE.raw_data_dir)\n",
    "# Get path for files needed to prepare data for model A3\n",
    "CHARACTER_DATA = core.get_path(core.A3.raw_data_dir)\n",
    "\n",
    "# File paths to save prepared transfer learning data to train base model A3\n",
    "TL_INPUT_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}input\")\n",
    "TL_OUTPUT_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}output\")\n",
    "TL_COMBINED_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}combined\")\n",
    "\n",
    "# File paths to save prepared data for training model A3\n",
    "PIX2PIX_INPUT_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}input\")\n",
    "PIX2PIX_OUTPUT_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}output\")\n",
    "PIX2PIX_COMBINED_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}combined\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(187)\n",
    "\n",
    "# Sorted list of images needed to prepare transfer learning data (data for base model A3)\n",
    "transfer_learn_images = sorted(list(glob.glob(TRANSFER_LEARNING_DATA + \"/*.png\")))\n",
    "# Sorted list of TinyHero images to prepare data for model A3\n",
    "character_images = sorted(list(glob.glob(CHARACTER_DATA + \"/*.png\")))\n",
    "\n",
    "# Shuffle lists of images\n",
    "random.shuffle(transfer_learn_images)\n",
    "random.shuffle(character_images)\n",
    "\n",
    "# Folder names to store train, test, validation data\n",
    "split_folders = (\"train\", \"test\", \"val\")"
   ],
   "id": "cb862630e69e0041",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Folder structure for model A3 data folder\n",
    "\n",
    "```\n",
    "model_a3_data\n",
    "    # Prepared data for Pix2Pix model\n",
    "    -- pix2pix_input (input images)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "    -- pix2pix_output (target images)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "    -- pix2pix_combined (combined input, target image pairs to use for Pix2Pix training)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "\n",
    "    # Prepared data for transfer learning\n",
    "    -- tl_input (input images)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "    -- tl_output (target images)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "    -- tl_combined (combined input, target image pairs to use for Pix2Pix training)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "```"
   ],
   "id": "ba8a4fa83a406e58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "32e853f27d0a1118"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:04.505008Z",
     "start_time": "2024-08-01T19:14:04.501173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(input_images, model_inp_dir, model_out_dir, split = (0.8, 0.9, 1.0)):\n",
    "    \"\"\"\n",
    "    Function to prepare data folders\n",
    "    :param input_images: original images\n",
    "    :param model_inp_dir: folder for storing prepared sketches\n",
    "    :param model_out_dir: folder for storing target images (ground truth images)\n",
    "    :param split: split points for train, test, validation\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    sketch_counter = 0\n",
    "    # Get split point for train data (0 -> train_end)\n",
    "    train_end = int(len(input_images) * split[0])\n",
    "    # Get split point for test data (train_end -> test_end)\n",
    "    # Validation data is from test_end -> end\n",
    "    test_end = int(len(input_images) * split[1])\n",
    "    \n",
    "    # 3 sketches will be created per image\n",
    "    sketch_per_img = 3\n",
    "    \n",
    "    # Outer for loop to iterate through input images\n",
    "    for image in input_images:\n",
    "        # Load and resize image with magenta background to 64x64\n",
    "        # then convert to OpenCV image\n",
    "        magenta_bg_image = core.pil_to_opencv(core.load_64x64_with_magenta_bg(image))\n",
    "        \n",
    "        # Inner for loop to iterate through sketches created per image\n",
    "        for sketch in range(1, sketch_per_img + 1):\n",
    "            # Create sketch using levels=sketch parameter to decide the level of detail in the sketch\n",
    "            # The higher the 'levels' parameter -> smoother the sketching\n",
    "            sketch_image = core.create_sketch(magenta_bg_image, levels=sketch, magenta_bg=True)\n",
    "            # Zero padded file names\n",
    "            filename = f\"{sketch_counter:05}.png\"\n",
    "            # Set 'current_split_folder' to train data folder\n",
    "            current_split_folder = split_folders[0]\n",
    "            # Then set 'current_split_folder' based on 'counter' variable\n",
    "            if train_end < counter < test_end:\n",
    "                current_split_folder = split_folders[1] # test data folder\n",
    "            elif counter >= test_end:\n",
    "                current_split_folder = split_folders[2] # validation data folder\n",
    "            \n",
    "            # ----------- Write to model_input and output directories -----------\n",
    "            model_input_path = os.path.join(model_inp_dir, current_split_folder)\n",
    "            os.makedirs(model_input_path, exist_ok=True)\n",
    "            core.write_image(sketch_image, os.path.join(model_input_path, filename))\n",
    "            \n",
    "            model_out_path = os.path.join(model_out_dir, current_split_folder)\n",
    "            os.makedirs(model_out_path, exist_ok=True)\n",
    "            core.write_image(magenta_bg_image, os.path.join(model_out_path, filename))\n",
    "            sketch_counter += 1\n",
    "        counter += 1"
   ],
   "id": "43fff89343792404",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:12.637054Z",
     "start_time": "2024-08-01T19:14:04.505844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data for transfer learning Pix2Pix (A3 base model)\n",
    "prepare_data(transfer_learn_images, TL_INPUT_DATA, TL_OUTPUT_DATA)"
   ],
   "id": "a3c70de128ebc7d9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:14.265242Z",
     "start_time": "2024-08-01T19:14:12.637869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data for final A3 Pix2Pix\n",
    "prepare_data(character_images, PIX2PIX_INPUT_DATA, PIX2PIX_OUTPUT_DATA)"
   ],
   "id": "4d20734b15a1226b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:20.282992Z",
     "start_time": "2024-08-01T19:14:14.268487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create combined images of input and ground truth images needed for transfer learning (base A3 model)\n",
    "os.makedirs(TL_COMBINED_DATA, exist_ok=True)\n",
    "core.create_combined_images(f\"--fold_A {TL_INPUT_DATA} --fold_B {TL_OUTPUT_DATA} --fold_AB {TL_COMBINED_DATA} --no_multiprocessing\")"
   ],
   "id": "ed0c36118eb41f0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "python /Users/tashvit/Documents/GitHub/mmpixagen/thirdparty/pix2pix/datasets/combine_A_and_B.py --fold_A /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_input --fold_B /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_output --fold_AB /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_combined --no_multiprocessing\n",
      "[fold_A] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_input\n",
      "[fold_B] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_output\n",
      "[fold_AB] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_combined\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  True\n",
      "split = test, use 1014/1014 images\n",
      "split = test, number of images = 1014\n",
      "split = train, use 8127/8127 images\n",
      "split = train, number of images = 8127\n",
      "split = val, use 1017/1017 images\n",
      "split = val, number of images = 1017\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:21.736431Z",
     "start_time": "2024-08-01T19:14:20.283548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create combined images of input and ground truth images for final A3 model\n",
    "os.makedirs(PIX2PIX_COMBINED_DATA, exist_ok=True)\n",
    "core.create_combined_images(f\"--fold_A {PIX2PIX_INPUT_DATA} --fold_B {PIX2PIX_OUTPUT_DATA} --fold_AB {PIX2PIX_COMBINED_DATA} --no_multiprocessing\")"
   ],
   "id": "f571453387f91c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "python /Users/tashvit/Documents/GitHub/mmpixagen/thirdparty/pix2pix/datasets/combine_A_and_B.py --fold_A /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_input --fold_B /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_output --fold_AB /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_combined --no_multiprocessing\n",
      "[fold_A] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_input\n",
      "[fold_B] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_output\n",
      "[fold_AB] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_combined\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  True\n",
      "split = test, use 270/270 images\n",
      "split = test, number of images = 270\n",
      "split = train, use 2190/2190 images\n",
      "split = train, number of images = 2190\n",
      "split = val, use 276/276 images\n",
      "split = val, number of images = 276\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:14:21.738741Z",
     "start_time": "2024-08-01T19:14:21.737334Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8a44f344b09e6b7e",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

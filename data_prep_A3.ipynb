{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data preparation - sketch to pixel art (Model A3)\n",
    "\n",
    "### Create pairs of sketches and pixel art images\n",
    "\n",
    "- TinyHero dataset source: https://www.kaggle.com/datasets/calmness/retro-pixel-characters-generator\n",
    "- Data for transfer learning:\n",
    "    - Anime Faces dataset source: https://www.kaggle.com/datasets/soumikrakshit/anime-faces\n",
    "    - Pokemon data source: https://www.kaggle.com/datasets/zackseliger/pokemon-images-includes-fakemon\n",
    "    - Animal Pack game assets source: https://kenney.nl/assets/animal-pack-redux\n",
    "- Data preparation for model A3 uses data from the `datasets/unprepared_data/input_a3` folder.\n",
    "- Prepared data will be saved in `datasets/model_a3_data`"
   ],
   "id": "8d011b188d0b8114"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:25.933669Z",
     "start_time": "2024-07-20T22:47:25.811488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, glob, random\n",
    "import common_functions as core\n",
    "\n",
    "# Get path for files needed to prepare data for transfer learning (base model A3)\n",
    "TRANSFER_LEARNING_DATA = core.get_path(core.A3_BASE.raw_data_dir)\n",
    "# Get path for files needed to prepare data for model A3\n",
    "CHARACTER_DATA = core.get_path(core.A3.raw_data_dir)\n",
    "\n",
    "# File paths to save prepared transfer learning data to train base model A3\n",
    "TL_INPUT_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}input\")\n",
    "TL_OUTPUT_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}output\")\n",
    "TL_COMBINED_DATA = core.get_path(core.A3_BASE.prepared_data_dir, f\"{core.A3_BASE.dataset_path_prefix}combined\")\n",
    "\n",
    "# File paths to save prepared data for training model A3\n",
    "PIX2PIX_INPUT_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}input\")\n",
    "PIX2PIX_OUTPUT_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}output\")\n",
    "PIX2PIX_COMBINED_DATA = core.get_path(core.A3.prepared_data_dir, f\"{core.A3.dataset_path_prefix}combined\")\n",
    "\n",
    "random.seed(187)\n",
    "\n",
    "# Sorted list of images needed to prepare transfer learning data (data for base model A3)\n",
    "transfer_learn_images = sorted(list(glob.glob(TRANSFER_LEARNING_DATA + \"/*.png\")))\n",
    "# Sorted list of TinyHero images to prepare data for model A3\n",
    "character_images = sorted(list(glob.glob(CHARACTER_DATA + \"/*.png\")))\n",
    "\n",
    "# Shuffle lists of images\n",
    "random.shuffle(transfer_learn_images)\n",
    "random.shuffle(character_images)\n",
    "\n",
    "# Folder names to store train, test, validation data\n",
    "split_folders = (\"train\", \"test\", \"val\")"
   ],
   "id": "cb862630e69e0041",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Folder structure for model A3 data folder\n",
    "\n",
    "```\n",
    "model_a3_data\n",
    "    # Prepared data for Pix2Pix model\n",
    "    -- pix2pix_input (input images)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "    -- pix2pix_output (target images)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "    -- pix2pix_combined (combined input, target image pairs to use for Pix2Pix training)\n",
    "        -- train\n",
    "        -- test\n",
    "        -- val\n",
    "\n",
    "    # Prepared data for transfer learning\n",
    "    -- tl_input (input images)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "    -- tl_output (target images)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "    -- tl_combined (combined input, target image pairs to use for Pix2Pix training)\n",
    "            -- train\n",
    "            -- test\n",
    "            -- val\n",
    "```"
   ],
   "id": "ba8a4fa83a406e58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "32e853f27d0a1118"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:25.943939Z",
     "start_time": "2024-07-20T22:47:25.938124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(input_images, model_inp_dir, model_out_dir, split = (0.8, 0.9, 1.0)):\n",
    "    counter = 0\n",
    "    train_end = int(len(input_images) * split[0])\n",
    "    test_end = int(len(input_images) * split[1])\n",
    "    sketch_per_img = 3\n",
    "    for image in input_images:\n",
    "        magenta_bg_image = core.pil_to_opencv(core.load_64x64_with_magenta_bg(image))\n",
    "        for sketch in range(1, sketch_per_img + 1):\n",
    "            sketch_image = core.create_sketch(magenta_bg_image, levels=sketch, magenta_bg=True)\n",
    "            filename = f\"{counter:05}.png\"\n",
    "            current_split_folder = split_folders[0]\n",
    "            if train_end < counter < test_end:\n",
    "                current_split_folder = split_folders[1]\n",
    "            elif counter >= test_end:\n",
    "                current_split_folder = split_folders[2]\n",
    "            # ----------- Write to model_input and output directories -----------\n",
    "            model_input_path = os.path.join(model_inp_dir, current_split_folder)\n",
    "            os.makedirs(model_input_path, exist_ok=True)\n",
    "            core.write_image(sketch_image, os.path.join(model_input_path, filename))\n",
    "            \n",
    "            model_out_path = os.path.join(model_out_dir, current_split_folder)\n",
    "            os.makedirs(model_out_path, exist_ok=True)\n",
    "            core.write_image(magenta_bg_image, os.path.join(model_out_path, filename))\n",
    "            \n",
    "            counter += 1"
   ],
   "id": "43fff89343792404",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:33.663501Z",
     "start_time": "2024-07-20T22:47:25.945371Z"
    }
   },
   "cell_type": "code",
   "source": "prepare_data(transfer_learn_images, TL_INPUT_DATA, TL_OUTPUT_DATA)",
   "id": "a3c70de128ebc7d9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:35.262792Z",
     "start_time": "2024-07-20T22:47:33.664110Z"
    }
   },
   "cell_type": "code",
   "source": "prepare_data(character_images, PIX2PIX_INPUT_DATA, PIX2PIX_OUTPUT_DATA)",
   "id": "4d20734b15a1226b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:35.265197Z",
     "start_time": "2024-07-20T22:47:35.263976Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5ab67021c70d544d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:39.507922Z",
     "start_time": "2024-07-20T22:47:35.265631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(TL_COMBINED_DATA, exist_ok=True)\n",
    "core.create_combined_images(f\"--fold_A {TL_INPUT_DATA} --fold_B {TL_OUTPUT_DATA} --fold_AB {TL_COMBINED_DATA} --no_multiprocessing\")"
   ],
   "id": "ed0c36118eb41f0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "python /Users/tashvit/Documents/GitHub/mmpixagen/thirdparty/pix2pix/datasets/combine_A_and_B.py --fold_A /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_input/ --fold_B /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_output/ --fold_AB /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_combined/ --no_multiprocessing\n",
      "[fold_A] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_input/\n",
      "[fold_B] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_output/\n",
      "[fold_AB] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/tl_combined/\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  True\n",
      "split = test, use 338/338 images\n",
      "split = test, number of images = 338\n",
      "split = train, use 2709/2709 images\n",
      "split = train, number of images = 2709\n",
      "split = val, use 7111/7111 images\n",
      "split = val, number of images = 7111\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:40.621208Z",
     "start_time": "2024-07-20T22:47:39.508567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(PIX2PIX_COMBINED_DATA, exist_ok=True)\n",
    "core.create_combined_images(f\"--fold_A {PIX2PIX_INPUT_DATA} --fold_B {PIX2PIX_OUTPUT_DATA} --fold_AB {PIX2PIX_COMBINED_DATA} --no_multiprocessing\")"
   ],
   "id": "f571453387f91c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "python /Users/tashvit/Documents/GitHub/mmpixagen/thirdparty/pix2pix/datasets/combine_A_and_B.py --fold_A /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_input/ --fold_B /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_output/ --fold_AB /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_combined/ --no_multiprocessing\n",
      "[fold_A] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_input/\n",
      "[fold_B] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_output/\n",
      "[fold_AB] =  /Users/tashvit/Documents/GitHub/mmpixagen/datasets/model_a3_data/pix2pix_combined/\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  True\n",
      "split = test, use 90/90 images\n",
      "split = test, number of images = 90\n",
      "split = train, use 730/730 images\n",
      "split = train, number of images = 730\n",
      "split = val, use 1916/1916 images\n",
      "split = val, number of images = 1916\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T22:47:40.623641Z",
     "start_time": "2024-07-20T22:47:40.622067Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8a44f344b09e6b7e",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
